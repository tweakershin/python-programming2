{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2．학습 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 라이브러리 임포트\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# OS 패키지 임포트\n",
    "import os\n",
    "# Pillow 라이브러리 임포트\n",
    "from PIL import Image\n",
    "# NumPy 라이브러리 임포트\n",
    "import numpy as np\n",
    "# pandas 라이브러리 임포트\n",
    "import pandas as pd\n",
    "# scikit-learn 라이브러리 임포트\n",
    "from sklearn import datasets, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대상 이미지 폴더 지정\n",
    "dirs = ['ants', 'bees']\n",
    "\n",
    "# 이미지의 픽셀값과 레이블을 저장할 리스트 초기화\n",
    "data = [] # 설명변수\n",
    "label = [] # 목적변수\n",
    "\n",
    "# 각 폴더의 이미지 파일을 하나씩 읽어 들이여 가공하고 리스트에 추가\n",
    "for i, d in enumerate(dirs):\n",
    "    # 파일 목록 생성\n",
    "    files = os.listdir('./data/hymenoptera_data/' + d)\n",
    "    \n",
    "    for f in files:\n",
    "        # 이미지 읽어 들이기\n",
    "        img = Image.open('./data/hymenoptera_data/' + d + '/' + f, 'r')\n",
    "        # 128 * 128로 리사이징\n",
    "        resize_img = img.resize((128, 128))\n",
    "        # 채널별로 분리해서 [0,1] 구간으로 정규화\n",
    "        resize_img.split()\n",
    "        r_resize_img = np.asarray(np.float32(r)/255.0)\n",
    "        g_resize_img = np.asarray(np.float32(g)/255.0)\n",
    "        b_resize_img = np.asarray(np.float32(b)/255.0)\n",
    "        rgb_resize_img = np.asarray([r_resize_img, g_resize_img, b_resize_img])\n",
    "        # 가공된 이미지를 리스트에 추가\n",
    "        data.append(rgb_resize_img)\n",
    "        \n",
    "        # 이미지 레이블을 리스트에 추가\n",
    "        label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 설명변수를 데이터프레임으로 변환해서 화면에 출력\n",
    "pd.DataFrame(data[0][0]) # R채널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적변수를 화면에 출력\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy 배열로 변환\n",
    "data = np.array(data, dtype='float32')\n",
    "label = np.array(label, dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 집합을 훈련 데이터와 테스트 데이터로 분할\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split(\n",
    "    data, label, test_size=0.1)\n",
    "\n",
    "# 데이터 건수를 확인\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3．텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 텐서 변환\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()\n",
    "\n",
    "# 텐서 크기를 화면에 출력\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 설명변수와 목적변수 텐서를 합치기\n",
    "train = TensorDataset(train_X, train_Y)\n",
    "\n",
    "# 첫 번째 텐서의 내용을 화면에 출력\n",
    "print(train[0])\n",
    "\n",
    "# 미니배치로 분할하기\n",
    "train_loader = DataLoader(train, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4．신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구성\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 합성곱층\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5) # 입력 채널 수, 출력 채널 수, 필터 크기\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "\n",
    "        # 전결합층\n",
    "        self.fc1 = nn.Linear(20 * 29 * 29, 50) # 29=(((((128-5)+1)/2)-5)+1)/2\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 풀링층\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # 풀링 영역 크기\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 20 * 29 * 29)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "# 인스턴스 생성\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5．모형 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차함수 객체\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    # 분할해 둔 데이터를 꺼내옴\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data[0]\n",
    "    # 50회 반복마다 누적오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy 배열로 변환\n",
    "test_X = np.array(test_X, dtype='float32')\n",
    "test_Y = np.array(test_Y, dtype='int64')\n",
    "\n",
    "# 테스트 데이터를 텐서로 변환\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()\n",
    "\n",
    "# 텐서 크기 확인\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계산 그래프 구성\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "# 출력이 0 혹은 1이 되게 함\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "# 모형의 정확도 측정\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
